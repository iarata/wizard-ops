# Main Cloud Build configuration for full pipeline deployment
# This orchestrates: Train → Deploy Backend → Deploy Frontend
# Trigger: Manual or on specific tags like "v*" or "release-*"
#
# Settings from configs/config.yaml are used as defaults

substitutions:
  _REGION: "europe-west4"
  _BUCKET: "dtu-kfc-bucket"
  # Training configuration - empty means use config.yaml defaults
  _EXPERIMENT_NAME: ""
  _BACKBONE: ""
  _MAX_EPOCHS: ""
  _BATCH_SIZE: ""
  _FAST_DEV_RUN: ""
  # Service configuration (matches config.yaml gcp section)
  _API_MEMORY: "2Gi"
  _FRONTEND_MEMORY: "512Mi"
  # Checkpoint path format: checkpoints/nutrition_{backbone}_{experiment_name}/final_model.ckpt
  _CHECKPOINT_BLOB: "checkpoints/nutrition_resnet18_default_experiment/final_model.ckpt"
  # Skip training if only deploying serving components
  _SKIP_TRAINING: "false"

  # Vertex AI training configuration (GPU)
  _VERTEX_MACHINE_TYPE: "n1-standard-8"
  _VERTEX_ACCELERATOR_TYPE: "NVIDIA_TESLA_T4"
  _VERTEX_ACCELERATOR_COUNT: "1"
  # Service account used by the Vertex training job at runtime (must have GCS access)
  _VERTEX_SERVICE_ACCOUNT: "dtu-kfc-sa@${PROJECT_ID}.iam.gserviceaccount.com"

steps:
  # Step 0: Set up common variables (TAG and REGISTRY)
  - name: "gcr.io/cloud-builders/docker"
    id: "setup-vars"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        # SHORT_SHA and BUILD_ID are Cloud Build substitutions
        # SHORT_SHA is only available from GitHub triggers
        # BUILD_ID is always available
        SHORT_SHA_VAL="${SHORT_SHA}"
        BUILD_ID_VAL="${BUILD_ID}"

        if [ -n "$${SHORT_SHA_VAL}" ]; then
          TAG="$${SHORT_SHA_VAL}"
        else
          # Take first 8 chars of BUILD_ID for manual builds
          TAG=$$(echo "$${BUILD_ID_VAL}" | cut -c1-8)
        fi

        REGISTRY="europe-west4-docker.pkg.dev/$PROJECT_ID/container-registry"
        # Compute checkpoint path dynamically unless explicitly overridden
        EXP_NAME="${_EXPERIMENT_NAME}"
        BACKBONE_NAME="${_BACKBONE}"
        if [ -z "$${EXP_NAME}" ]; then EXP_NAME="default_experiment"; fi
        if [ -z "$${BACKBONE_NAME}" ]; then BACKBONE_NAME="resnet18"; fi

        CHECKPOINT_BLOB="${_CHECKPOINT_BLOB}"
        if [ -z "$${CHECKPOINT_BLOB}" ]; then
          CHECKPOINT_BLOB="checkpoints/nutrition_$${BACKBONE_NAME}_$${EXP_NAME}/final_model.ckpt"
        fi

        echo "TAG=$${TAG}" > /workspace/build-vars.env
        echo "REGISTRY=$${REGISTRY}" >> /workspace/build-vars.env
        echo "CHECKPOINT_BLOB=$${CHECKPOINT_BLOB}" >> /workspace/build-vars.env
        echo "Build Tag: $${TAG}"
        echo "Registry: $${REGISTRY}"
        echo "Checkpoint Blob: $${CHECKPOINT_BLOB}"

  # ==================== TRAINING PHASE ====================

  # Step 1: Build training image (skip if _SKIP_TRAINING is true)
  - name: "gcr.io/cloud-builders/docker"
    id: "build-train-image"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        if [ "${_SKIP_TRAINING}" = "true" ]; then
          echo "Skipping training build..."
          exit 0
        fi
        source /workspace/build-vars.env
        docker build -f dockerfiles/train.dockerfile \
          -t $${REGISTRY}/wizard-ops-train:$${TAG} \
          -t $${REGISTRY}/wizard-ops-train:latest \
          .
    waitFor: ["setup-vars"]

  # Step 2: Push training image
  - name: "gcr.io/cloud-builders/docker"
    id: "push-train-image"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        if [ "${_SKIP_TRAINING}" = "true" ]; then
          echo "Skipping training push..."
          exit 0
        fi
        source /workspace/build-vars.env
        docker push $${REGISTRY}/wizard-ops-train:$${TAG}
        docker push $${REGISTRY}/wizard-ops-train:latest
    waitFor: ["build-train-image"]

  # Step 3: Run training
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: "run-training"
    entrypoint: "bash"
    secretEnv: ["WANDB_API_KEY"]
    args:
      - "-c"
      - |
        if [ "${_SKIP_TRAINING}" = "true" ]; then
          echo "Skipping training..."
          exit 0
        fi
        source /workspace/build-vars.env

        JOB_NAME="wizard-ops-train-$${TAG}-$(date +%Y%m%d%H%M%S)"
        echo "Submitting Vertex AI Custom Job: $${JOB_NAME}"

        JOB_RESOURCE=$$(gcloud ai custom-jobs create \
          --region=${_REGION} \
          --display-name=$${JOB_NAME} \
          --worker-pool-spec=machine-type=${_VERTEX_MACHINE_TYPE},accelerator-type=${_VERTEX_ACCELERATOR_TYPE},accelerator-count=${_VERTEX_ACCELERATOR_COUNT},replica-count=1,container-image-uri=$${REGISTRY}/wizard-ops-train:$${TAG} \
          --env-vars="EXPERIMENT_NAME=${_EXPERIMENT_NAME},BACKBONE=${_BACKBONE},MAX_EPOCHS=${_MAX_EPOCHS},BATCH_SIZE=${_BATCH_SIZE},FAST_DEV_RUN=${_FAST_DEV_RUN},WANDB_API_KEY=$$WANDB_API_KEY" \
          --service-account="${_VERTEX_SERVICE_ACCOUNT}" \
          --format='value(name)')

        if [ -z "$${JOB_RESOURCE}" ]; then
          echo "Failed to get Vertex job resource name."
          exit 1
        fi

        echo "Vertex job resource: $${JOB_RESOURCE}"
        echo "Monitor at: https://console.cloud.google.com/vertex-ai/training/custom-jobs?project=${PROJECT_ID}"

        echo "Waiting for Vertex AI job to finish..."
        while true; do
          STATE=$$(gcloud ai custom-jobs describe "$${JOB_RESOURCE}" --region=${_REGION} --format='value(state)')
          echo "Vertex job state: $${STATE}"
          if [ "$${STATE}" = "JOB_STATE_SUCCEEDED" ]; then
            break
          fi
          if [ "$${STATE}" = "JOB_STATE_FAILED" ] || [ "$${STATE}" = "JOB_STATE_CANCELLED" ]; then
            echo "Vertex job did not succeed."
            exit 1
          fi
          sleep 60
        done
    waitFor: ["push-train-image"]

  # ==================== BACKEND DEPLOYMENT PHASE ====================

  # Step 4: Build backend API image
  - name: "gcr.io/cloud-builders/docker"
    id: "build-api-image"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        source /workspace/build-vars.env
        docker build -f dockerfiles/api.dockerfile \
          --build-arg BUCKET_NAME=${_BUCKET} \
          --build-arg CHECKPOINT_BLOB=$${CHECKPOINT_BLOB} \
          -t $${REGISTRY}/wizard-ops-api:$${TAG} \
          -t $${REGISTRY}/wizard-ops-api:latest \
          .
    waitFor: ["run-training"]

  # Step 5: Push backend image
  - name: "gcr.io/cloud-builders/docker"
    id: "push-api-image"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        source /workspace/build-vars.env
        docker push $${REGISTRY}/wizard-ops-api:$${TAG}
        docker push $${REGISTRY}/wizard-ops-api:latest
    waitFor: ["build-api-image"]

  # Step 6: Deploy backend to Cloud Run
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: "deploy-api"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        source /workspace/build-vars.env
        gcloud run deploy wizard-ops-api \
          --image $${REGISTRY}/wizard-ops-api:$${TAG} \
          --region ${_REGION} \
          --platform managed \
          --memory ${_API_MEMORY} \
          --allow-unauthenticated \
          --set-env-vars "BUCKET_NAME=${_BUCKET},CHECKPOINT_BLOB=$${CHECKPOINT_BLOB}"
    waitFor: ["push-api-image"]

  # Step 7: Get backend URL
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: "get-backend-url"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        BACKEND_URL=$$(gcloud run services describe wizard-ops-api --region=${_REGION} --format='value(status.url)')
        echo "$${BACKEND_URL}" > /workspace/backend_url.txt
        echo "Backend deployed at: $${BACKEND_URL}"
    waitFor: ["deploy-api"]

  # ==================== FRONTEND DEPLOYMENT PHASE ====================

  # Step 8: Build frontend image
  - name: "gcr.io/cloud-builders/docker"
    id: "build-frontend-image"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        source /workspace/build-vars.env
        docker build -f dockerfiles/frontend.dockerfile \
          -t $${REGISTRY}/streamlit-app:$${TAG} \
          -t $${REGISTRY}/streamlit-app:latest \
          .
    waitFor: ["get-backend-url"]

  # Step 9: Push frontend image
  - name: "gcr.io/cloud-builders/docker"
    id: "push-frontend-image"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        source /workspace/build-vars.env
        docker push $${REGISTRY}/streamlit-app:$${TAG}
        docker push $${REGISTRY}/streamlit-app:latest
    waitFor: ["build-frontend-image"]

  # Step 10: Deploy frontend to Cloud Run
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: "deploy-frontend"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        source /workspace/build-vars.env
        BACKEND_URL=$$(cat /workspace/backend_url.txt)
        gcloud run deploy streamlit-app \
          --image $${REGISTRY}/streamlit-app:$${TAG} \
          --region ${_REGION} \
          --platform managed \
          --memory ${_FRONTEND_MEMORY} \
          --allow-unauthenticated \
          --set-env-vars "WIZARD_BACKEND=$${BACKEND_URL}"
    waitFor: ["push-frontend-image"]

  # Step 11: Output deployment summary
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: "deployment-summary"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        source /workspace/build-vars.env
        echo "============================================"
        echo "           DEPLOYMENT COMPLETE             "
        echo "============================================"
        BACKEND_URL=$$(cat /workspace/backend_url.txt)
        FRONTEND_URL=$$(gcloud run services describe streamlit-app --region=${_REGION} --format='value(status.url)')
        echo ""
        echo "Backend API:  $${BACKEND_URL}"
        echo "Frontend App: $${FRONTEND_URL}"
        echo ""
        echo "Build Tag: $${TAG}"
        echo "Experiment: ${_EXPERIMENT_NAME}"
        echo "============================================"
    waitFor: ["deploy-frontend"]

# Note: We don't use the 'images' section because we push manually with dynamic tags
# This avoids issues with SHORT_SHA being empty in manual builds

availableSecrets:
  secretManager:
    - versionName: "projects/$PROJECT_ID/secrets/wandb-api-key/versions/latest"
      env: "WANDB_API_KEY"

options:
  logging: CLOUD_LOGGING_ONLY
  machineType: "E2_HIGHCPU_8"
  diskSizeGb: 100

timeout: "10800s" # 3 hours for full pipeline
